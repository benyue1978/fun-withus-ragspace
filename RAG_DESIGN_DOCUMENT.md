# RAGSpace RAG ç³»ç»Ÿè®¾è®¡æ–‡æ¡£

## æ¦‚è¿°

æœ¬æ–‡æ¡£æè¿°äº†RAGSpaceé¡¹ç›®ä¸­RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿçš„å®Œæ•´è®¾è®¡æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å‘é‡æ•°æ®åº“é…ç½®ã€æ–‡æ¡£åˆ†ç‰‡ç­–ç•¥ã€åµŒå…¥æµç¨‹ã€æ£€ç´¢æœºåˆ¶å’Œç”¨æˆ·ç•Œé¢é›†æˆã€‚

## ç³»ç»Ÿæ¶æ„

### æ•°æ®æµå›¾

```mermaid
graph TD
    A[ç”¨æˆ·ä¸Šä¼ /æ·»åŠ æ–‡æ¡£] --> B[å†…å®¹æå–å™¨]
    B --> C[æ–‡æ¡£åˆ†ç‰‡å™¨]
    C --> D[åµŒå…¥ç”Ÿæˆå™¨]
    D --> E[å‘é‡æ•°æ®åº“å­˜å‚¨]
    E --> F[æ£€ç´¢ç³»ç»Ÿ]
    F --> G[é‡æ’åº]
    G --> H[LLMç”Ÿæˆ]
    H --> I[ç»“æœå±•ç¤º]
    
    J[ç”¨æˆ·æŸ¥è¯¢] --> F
    K[DocSeté€‰æ‹©] --> F
```

## 1. å‘é‡æ•°æ®åº“é…ç½®

### 1.1 Supabase pgvector è®¾ç½®

#### å¯ç”¨å‘é‡æ‰©å±•
```sql
-- åœ¨ Supabase SQL Editor ä¸­æ‰§è¡Œ
CREATE EXTENSION IF NOT EXISTS vector;
```

#### åˆ›å»ºåˆ†ç‰‡è¡¨
```sql
CREATE TABLE chunks (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  docset_name TEXT NOT NULL,
  document_name TEXT NOT NULL,
  chunk_index INTEGER NOT NULL,
  content TEXT NOT NULL,
  embedding VECTOR(1536), -- OpenAI text-embedding-3-small ç»´åº¦
  metadata JSONB DEFAULT '{}',
  created_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºå‘é‡ç´¢å¼•
CREATE INDEX ON chunks USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_chunks_docset_document ON chunks(docset_name, document_name);
CREATE INDEX idx_chunks_metadata ON chunks USING GIN (metadata);
```

### 1.2 æ–‡æ¡£çŠ¶æ€ç®¡ç†

#### æ›´æ–°documentsè¡¨
```sql
-- æ·»åŠ åµŒå…¥çŠ¶æ€å­—æ®µ
ALTER TABLE documents ADD COLUMN IF NOT EXISTS embedding_status TEXT 
DEFAULT 'pending' CHECK (embedding_status IN ('pending', 'processing', 'done', 'error'));

-- æ·»åŠ åµŒå…¥æ—¶é—´å­—æ®µ
ALTER TABLE documents ADD COLUMN IF NOT EXISTS embedding_updated_at TIMESTAMP;
```

## 2. åµŒå…¥æµç¨‹è®¾è®¡

### 2.1 å¼‚æ­¥å¤„ç†æ¶æ„

```python
# åµŒå…¥å·¥ä½œæµç¨‹
ç”¨æˆ·æ·»åŠ æ–‡æ¡£ â†’ çŠ¶æ€è®¾ä¸ºpending â†’ å¼‚æ­¥åµŒå…¥å¤„ç† â†’ çŠ¶æ€æ›´æ–°ä¸ºdone
```

### 2.2 çŠ¶æ€ç®¡ç†

| çŠ¶æ€ | æè¿° | UIæ˜¾ç¤º |
|------|------|--------|
| `pending` | ç­‰å¾…åµŒå…¥å¤„ç† | ğŸŸ¡ ç­‰å¾…å¤„ç† |
| `processing` | æ­£åœ¨åµŒå…¥ | â³ å¤„ç†ä¸­... |
| `done` | åµŒå…¥å®Œæˆ | âœ… å·²å®Œæˆ |
| `error` | åµŒå…¥å¤±è´¥ | âŒ å¤„ç†å¤±è´¥ |

## 3. æ–‡æ¡£åˆ†ç‰‡ç­–ç•¥

### 3.1 æ–‡æœ¬ç±»æ–‡æ¡£åˆ†ç‰‡

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

def create_text_splitter():
    return RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=100,
        separators=["\n\n", "\n", ".", " "],
        length_function=len
    )
```

### 3.2 ä»£ç ç±»æ–‡æ¡£åˆ†ç‰‡

```python
def create_code_splitter():
    return RecursiveCharacterTextSplitter(
        chunk_size=300,
        chunk_overlap=50,
        separators=["\nclass ", "\ndef ", "\n", " "],
        length_function=len
    )
```

### 3.3 åˆ†ç‰‡ç­–ç•¥é€‰æ‹©

```python
def get_splitter_for_document(doc_type: str):
    """æ ¹æ®æ–‡æ¡£ç±»å‹é€‰æ‹©åˆé€‚çš„åˆ†ç±»å™¨"""
    if doc_type in ['github_file', 'code']:
        return create_code_splitter()
    else:
        return create_text_splitter()
```

## 4. å…ƒæ•°æ®è®¾è®¡

### 4.1 åˆ†ç‰‡å…ƒæ•°æ®ç»“æ„

```json
{
  "docset_name": "llama_index_tutorial",
  "document_name": "README.md",
  "source_type": "github",
  "url": "https://github.com/user/repo/blob/main/README.md",
  "start_line": 52,
  "end_line": 78,
  "chunk_index": 3,
  "language": "markdown",
  "file_path": "docs/README.md",
  "timestamp": "2024-12-01T13:00:00Z",
  "doc_type": "github_file",
  "repo": "owner/repo",
  "commit_id": "abc123..."
}
```

### 4.2 å…ƒæ•°æ®å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|------|------|------|
| `docset_name` | string | æ–‡æ¡£é›†åˆåç§° |
| `document_name` | string | æ–‡æ¡£åç§° |
| `source_type` | string | æ¥æºç±»å‹ï¼ˆgithub/website/fileï¼‰ |
| `url` | string | åŸå§‹URL |
| `start_line` | integer | èµ·å§‹è¡Œå· |
| `end_line` | integer | ç»“æŸè¡Œå· |
| `chunk_index` | integer | åˆ†ç‰‡ç´¢å¼• |
| `language` | string | ç¼–ç¨‹è¯­è¨€ |
| `file_path` | string | æ–‡ä»¶è·¯å¾„ |
| `timestamp` | string | æ—¶é—´æˆ³ |
| `doc_type` | string | æ–‡æ¡£ç±»å‹ |
| `repo` | string | ä»“åº“ä¿¡æ¯ï¼ˆGitHubï¼‰ |
| `commit_id` | string | æäº¤IDï¼ˆGitHubï¼‰ |

## 5. åµŒå…¥æœåŠ¡

### 5.1 åµŒå…¥æ¨¡å‹é…ç½®

```python
# æ”¯æŒçš„åµŒå…¥æ¨¡å‹
EMBEDDING_MODELS = {
    "openai": {
        "model": "text-embedding-3-small",
        "dimensions": 1536,
        "api_key_env": "OPENAI_API_KEY"
    },
    "qwen": {
        "model": "text-embedding-v1",
        "dimensions": 1536,
        "api_key_env": "DASHSCOPE_API_KEY"
    }
}
```

### 5.2 åµŒå…¥å·¥ä½œå™¨

```python
class EmbeddingWorker:
    def __init__(self, model_name="openai"):
        self.model_name = model_name
        self.model_config = EMBEDDING_MODELS[model_name]
        self.client = self._init_client()
    
    def process_document(self, doc_id: str):
        """å¤„ç†å•ä¸ªæ–‡æ¡£çš„åµŒå…¥"""
        # 1. è·å–æ–‡æ¡£å†…å®¹
        # 2. åˆ†ç‰‡å¤„ç†
        # 3. ç”ŸæˆåµŒå…¥
        # 4. å­˜å‚¨åˆ°chunksè¡¨
        # 5. æ›´æ–°æ–‡æ¡£çŠ¶æ€
        pass
    
    def batch_process(self, docset_name: str = None):
        """æ‰¹é‡å¤„ç†å¾…åµŒå…¥çš„æ–‡æ¡£"""
        pass
```

## 6. æ£€ç´¢ç­–ç•¥

### 6.1 å‘é‡æ£€ç´¢

```python
def retrieve_chunks(query: str, docsets: List[str] = None, top_k: int = 5):
    """å‘é‡æ£€ç´¢ä¸»å‡½æ•°"""
    # 1. ç”ŸæˆæŸ¥è¯¢åµŒå…¥
    query_embedding = generate_embedding(query)
    
    # 2. æ„å»ºæŸ¥è¯¢
    query_builder = supabase.table("chunks").select("*")
    
    if docsets:
        query_builder = query_builder.in_("docset_name", docsets)
    
    # 3. å‘é‡ç›¸ä¼¼åº¦æœç´¢
    results = query_builder.order(
        f"embedding <-> '{query_embedding}'"
    ).limit(top_k).execute()
    
    return results.data
```

### 6.2 é‡æ’åºç­–ç•¥

#### æ–¹æ¡ˆä¸€ï¼šçº¯å‘é‡æ£€ç´¢
```python
def simple_retrieve(query: str, docsets: List[str] = None, top_k: int = 5):
    """ç®€å•å‘é‡æ£€ç´¢"""
    return retrieve_chunks(query, docsets, top_k)
```

#### æ–¹æ¡ˆäºŒï¼šGPTé‡æ’åºï¼ˆæ¨èï¼‰
```python
def gpt_rerank(query: str, chunks: List[Dict], top_k: int = 3):
    """ä½¿ç”¨GPTè¿›è¡Œé‡æ’åº"""
    prompt = f"""
    You are an expert technical assistant.
    
    Given the following user question and a list of code/document snippets retrieved from a knowledge base, rank the snippets by how relevant they are to answering the question.
    
    Question: {query}
    
    Snippets:
    {chr(10).join([f"{i+1}. {chunk['content'][:200]}..." for i, chunk in enumerate(chunks)])}
    
    Return the ranking as a JSON list of indices sorted from most to least relevant. Do not explain.
    Example: [2, 1, 3]
    """
    
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    
    ranking = json.loads(response.choices[0].message.content)
    return [chunks[i] for i in ranking[:top_k]]
```

### 6.3 æ··åˆæ£€ç´¢ç­–ç•¥

```python
def hybrid_retrieve(query: str, docsets: List[str] = None, top_k: int = 5, use_rerank: bool = True):
    """æ··åˆæ£€ç´¢ç­–ç•¥"""
    # 1. å‘é‡æ£€ç´¢è·å–å€™é€‰
    candidates = retrieve_chunks(query, docsets, top_k * 2)
    
    if not use_rerank:
        return candidates[:top_k]
    
    # 2. GPTé‡æ’åº
    return gpt_rerank(query, candidates, top_k)
```

## 7. UIé›†æˆè®¾è®¡

### 7.1 èŠå¤©ç•Œé¢å¢å¼º

```python
def create_chat_interface():
    """åˆ›å»ºå¢å¼ºçš„èŠå¤©ç•Œé¢"""
    with gr.Blocks() as chat_interface:
        # DocSeté€‰æ‹©å™¨
        docset_selector = gr.CheckboxGroup(
            choices=get_docsets_list(),
            label="é€‰æ‹©æ–‡æ¡£é›†åˆ",
            value=["all"],
            interactive=True
        )
        
        # èŠå¤©å†å²
        chatbot = gr.Chatbot(height=400)
        
        # æŸ¥è¯¢è¾“å…¥
        msg = gr.Textbox(label="è¾“å…¥é—®é¢˜")
        
        # æäº¤æŒ‰é’®
        submit = gr.Button("å‘é€")
        
        # æ¸…é™¤æŒ‰é’®
        clear = gr.Button("æ¸…é™¤")
        
        # äº‹ä»¶å¤„ç†
        submit.click(
            process_query_with_rag,
            inputs=[msg, chatbot, docset_selector],
            outputs=[chatbot, msg]
        )
        
        clear.click(lambda: ([], ""), outputs=[chatbot, msg])
    
    return chat_interface
```

### 7.2 åµŒå…¥çŠ¶æ€æ˜¾ç¤º

```python
def create_embedding_status_ui():
    """åˆ›å»ºåµŒå…¥çŠ¶æ€æ˜¾ç¤ºç•Œé¢"""
    with gr.Blocks() as status_ui:
        # çŠ¶æ€è¡¨æ ¼
        status_table = gr.Dataframe(
            headers=["æ–‡æ¡£åç§°", "æ–‡æ¡£é›†åˆ", "çŠ¶æ€", "æ›´æ–°æ—¶é—´"],
            datatype=["str", "str", "str", "str"],
            col_count=(4, "fixed"),
            interactive=False
        )
        
        # åˆ·æ–°æŒ‰é’®
        refresh_btn = gr.Button("åˆ·æ–°çŠ¶æ€")
        
        # æ‰‹åŠ¨è§¦å‘åµŒå…¥æŒ‰é’®
        trigger_embedding_btn = gr.Button("æ‰‹åŠ¨è§¦å‘åµŒå…¥")
        
        # äº‹ä»¶å¤„ç†
        refresh_btn.click(
            update_embedding_status,
            outputs=status_table
        )
        
        trigger_embedding_btn.click(
            trigger_embedding_process,
            outputs=status_table
        )
    
    return status_ui
```

### 7.3 æ£€ç´¢ç»“æœå±•ç¤º

```python
def display_retrieval_results(results: List[Dict]):
    """å±•ç¤ºæ£€ç´¢ç»“æœ"""
    markdown_content = ""
    
    for i, result in enumerate(results, 1):
        # æ„å»ºæºé“¾æ¥
        source_link = f"[{result['document_name']} (è¡Œ {result['metadata']['start_line']}-{result['metadata']['end_line']})]({result['metadata']['url']}#L{result['metadata']['start_line']}-L{result['metadata']['end_line']})"
        
        # æ„å»ºå†…å®¹å±•ç¤º
        content_preview = result['content'][:200] + "..." if len(result['content']) > 200 else result['content']
        
        markdown_content += f"""
        ### ç»“æœ {i}
        
        **æ¥æº**: {source_link}
        
        **å†…å®¹**:
        ```
        {content_preview}
        ```
        
        ---
        """
    
    return gr.Markdown(markdown_content)
```

## 8. å®ç°æ¨¡å—

### 8.1 æ ¸å¿ƒæ¨¡å—ç»“æ„

```
src/ragspace/
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embedding_worker.py      # åµŒå…¥å·¥ä½œå™¨
â”‚   â”œâ”€â”€ text_splitter.py        # æ–‡æœ¬åˆ†ç‰‡å™¨
â”‚   â”œâ”€â”€ retriever.py            # æ£€ç´¢å™¨
â”‚   â”œâ”€â”€ reranker.py             # é‡æ’åºå™¨
â”‚   â””â”€â”€ metadata_builder.py     # å…ƒæ•°æ®æ„å»ºå™¨
â”œâ”€â”€ config/
â”‚   â””â”€â”€ rag_config.py           # RAGé…ç½®
â””â”€â”€ ui/
    â””â”€â”€ components/
        â””â”€â”€ rag_chat.py         # RAGèŠå¤©ç»„ä»¶
```

### 8.2 é…ç½®ç®¡ç†

```python
# src/ragspace/config/rag_config.py
class RAGConfig:
    # åµŒå…¥é…ç½®
    EMBEDDING_MODEL = "openai"
    EMBEDDING_DIMENSIONS = 1536
    
    # åˆ†ç‰‡é…ç½®
    TEXT_CHUNK_SIZE = 500
    TEXT_CHUNK_OVERLAP = 100
    CODE_CHUNK_SIZE = 300
    CODE_CHUNK_OVERLAP = 50
    
    # æ£€ç´¢é…ç½®
    DEFAULT_TOP_K = 5
    RERANK_TOP_K = 3
    USE_RERANK = True
    
    # é‡æ’åºé…ç½®
    RERANK_MODEL = "gpt-3.5-turbo"
    RERANK_TEMPERATURE = 0
```

## 9. éƒ¨ç½²å’Œç›‘æ§

### 9.1 ç¯å¢ƒå˜é‡é…ç½®

```bash
# åµŒå…¥æ¨¡å‹é…ç½®
OPENAI_API_KEY=your-openai-api-key
DASHSCOPE_API_KEY=your-dashscope-api-key

# RAGé…ç½®
RAG_EMBEDDING_MODEL=openai
RAG_USE_RERANK=true
RAG_DEFAULT_TOP_K=5
```

### 9.2 ç›‘æ§æŒ‡æ ‡

- åµŒå…¥å¤„ç†æ—¶é—´
- æ£€ç´¢å“åº”æ—¶é—´
- é‡æ’åºå‡†ç¡®ç‡
- ç”¨æˆ·æ»¡æ„åº¦è¯„åˆ†

## 10. å®æ–½è®¡åˆ’

### é˜¶æ®µä¸€ï¼šåŸºç¡€æ¶æ„ï¼ˆ1-2å‘¨ï¼‰
- [ ] åˆ›å»ºchunksè¡¨
- [ ] å®ç°åŸºç¡€åµŒå…¥å·¥ä½œå™¨
- [ ] å®ç°ç®€å•æ£€ç´¢åŠŸèƒ½

### é˜¶æ®µäºŒï¼šUIé›†æˆï¼ˆ1å‘¨ï¼‰
- [ ] é›†æˆèŠå¤©ç•Œé¢
- [ ] æ·»åŠ DocSeté€‰æ‹©å™¨
- [ ] å®ç°çŠ¶æ€æ˜¾ç¤º

### é˜¶æ®µä¸‰ï¼šä¼˜åŒ–ï¼ˆ1å‘¨ï¼‰
- [ ] å®ç°GPTé‡æ’åº
- [ ] ä¼˜åŒ–æ£€ç´¢ç­–ç•¥
- [ ] æ·»åŠ ç›‘æ§å’Œæ—¥å¿—

### é˜¶æ®µå››ï¼šæµ‹è¯•å’Œéƒ¨ç½²ï¼ˆ1å‘¨ï¼‰
- [ ] å…¨é¢æµ‹è¯•
- [ ] æ€§èƒ½ä¼˜åŒ–
- [ ] ç”Ÿäº§éƒ¨ç½²

## 11. æŠ€æœ¯æ ˆ

### åç«¯
- **å‘é‡æ•°æ®åº“**: Supabase pgvector
- **åµŒå…¥æ¨¡å‹**: OpenAI text-embedding-3-small
- **é‡æ’åº**: GPT-3.5-turbo
- **åˆ†ç‰‡**: LangChain RecursiveCharacterTextSplitter

### å‰ç«¯
- **UIæ¡†æ¶**: Gradio
- **çŠ¶æ€ç®¡ç†**: Supabaseå®æ—¶è®¢é˜…
- **äº¤äº’**: å¼‚æ­¥å¤„ç† + çŠ¶æ€æ›´æ–°

## æ€»ç»“

æœ¬RAGç³»ç»Ÿè®¾è®¡æä¾›äº†å®Œæ•´çš„æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

1. âœ… **æ¨¡å—åŒ–è®¾è®¡**: å„ç»„ä»¶ç‹¬ç«‹ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
2. âœ… **å¼‚æ­¥å¤„ç†**: ä¸é˜»å¡ç”¨æˆ·ç•Œé¢
3. âœ… **æ™ºèƒ½æ£€ç´¢**: æ”¯æŒå‘é‡æ£€ç´¢ + GPTé‡æ’åº
4. âœ… **ç”¨æˆ·å‹å¥½**: ç›´è§‚çš„çŠ¶æ€æ˜¾ç¤ºå’Œç»“æœå±•ç¤º
5. âœ… **å¯æ‰©å±•**: æ”¯æŒå¤šç§åµŒå…¥æ¨¡å‹å’Œæ£€ç´¢ç­–ç•¥

é€šè¿‡è¿™ä¸ªè®¾è®¡ï¼ŒRAGSpaceå°†èƒ½å¤Ÿæä¾›é«˜è´¨é‡çš„æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”æœåŠ¡ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å¥½çš„çŸ¥è¯†ç®¡ç†ä½“éªŒã€‚

---

*è®¾è®¡æ–‡æ¡£ç‰ˆæœ¬: 1.0*  
*æ›´æ–°æ—¶é—´: 2024å¹´12æœˆ* 